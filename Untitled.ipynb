{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Roof_Type' has 339 missing observations\n",
      "Column 'Floors' has 269 missing observations\n",
      "Column 'House_Type' has 182 missing observations\n",
      "Column 'Shading' has 96 missing observations\n",
      "Column 'Roof_Azimuth' has 84 missing observations\n",
      "Column 'Latitude' has 70 missing observations\n",
      "Column 'Roof_Pitch' has 28 missing observations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:/Users/Faraz Ahmad/Downloads/SolarSurvey.csv\")\n",
    "\n",
    "# Count the number of missing values for each column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Filter columns with missing values\n",
    "missing_values = missing_values[missing_values != 0]\n",
    "\n",
    "# Sort the columns by the number of missing values in descending order\n",
    "missing_values = missing_values.sort_values(ascending=False)\n",
    "\n",
    "# Print out the column names and the number of missing observations associated with each\n",
    "for column_name, missing_count in missing_values.items():\n",
    "    print(f\"Column '{column_name}' has {missing_count} missing observations\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d59151d1194e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m    \u001b[1;31m# col_type = split_line[1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#col_desc = split_line[2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mdata_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Column Name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Data Type'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcol_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Description'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcol_desc\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'col_type' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:/Users/Faraz Ahmad/Downloads/SolarSurvey.csv\")\n",
    "\n",
    "# Load your data dictionary into a pandas DataFrame\n",
    "with open(\"C:/Users/Faraz Ahmad/Downloads/DataDictionary.txt\") as f:\n",
    "    data_dict_lines = f.readlines()\n",
    "\n",
    "# Convert the data dictionary text into a list of dictionaries\n",
    "data_dict = []\n",
    "for line in data_dict_lines:\n",
    "    split_line = line.strip().split('\\t')\n",
    "    col_name = split_line[0]\n",
    "   # col_type = split_line[1]\n",
    "    #col_desc = split_line[2]\n",
    "    data_dict.append({'Column Name': col_name, 'Data Type': col_type, 'Description': col_desc})\n",
    "data_dict = pd.DataFrame(data_dict)\n",
    "\n",
    "# Extract the column names from your dataset and data dictionary\n",
    "data_cols = set(df.columns)\n",
    "dict_cols = set(data_dict['Column Name'])\n",
    "\n",
    "# Check for missing columns in the data dictionary\n",
    "missing_cols = data_cols - dict_cols\n",
    "if missing_cols:\n",
    "    print(f\"Missing columns in data dictionary: {missing_cols}\")\n",
    "\n",
    "# Check for missing columns in the dataset\n",
    "missing_cols = dict_cols - data_cols\n",
    "if missing_cols:\n",
    "    print(f\"Missing columns in dataset: {missing_cols}\")\n",
    "\n",
    "# Check for discrepancies in column data types and descriptions\n",
    "for col in data_dict['Column Name']:\n",
    "    dict_type = data_dict.loc[data_dict['Column Name'] == col, 'Data Type'].iloc[0]\n",
    "    dict_desc = data_dict.loc[data_dict['Column Name'] == col, 'Description'].iloc[0]\n",
    "\n",
    "    data_type = str(df[col].dtype)\n",
    "    data_desc = df[col].describe().loc['top']\n",
    "\n",
    "    if data_type != dict_type:\n",
    "        print(f\"Data type discrepancy for column '{col}': expected {dict_type}, got {data_type}\")\n",
    "    if data_desc != dict_desc:\n",
    "        print(f\"Description discrepancy for column '{col}': expected {dict_desc}, got {data_desc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7c6ce67c5579>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdict_cols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"description\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Loop through each column in the dataset and compare the data type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:/Users/Faraz Ahmad/Downloads/SolarSurvey.csv\")\n",
    "\n",
    "# Load your data dictionary into a list\n",
    "with open(\"C:/Users/Faraz Ahmad/Downloads/DataDictionary.txt\", \"r\") as f:\n",
    "    dict_lines = f.readlines()\n",
    "\n",
    "# Create a dictionary to store the data types and descriptions\n",
    "# for each column in the data dictionary\n",
    "dict_cols = {}\n",
    "for line in dict_lines:\n",
    "    parts = line.strip().split(\":\")\n",
    "    dict_cols[parts[0]] = {\"type\": parts[1], \"description\": parts[2]}\n",
    "\n",
    "# Loop through each column in the dataset and compare the data type\n",
    "# and description to the data dictionary\n",
    "for col in df.columns:\n",
    "    if col in dict_cols:\n",
    "        data_type = str(df[col].dtype)\n",
    "        dict_type = dict_cols[col][\"type\"]\n",
    "        if data_type != dict_type:\n",
    "            print(f\"Data type for column '{col}' does not match data dictionary. Expected {dict_type}, got {data_type}.\")\n",
    "\n",
    "        data_desc = df[col].describe().loc['top']\n",
    "        dict_desc = dict_cols[col][\"description\"]\n",
    "        if data_desc != dict_desc:\n",
    "            print(f\"Description for column '{col}' does not match data dictionary. Expected '{dict_desc}', got '{data_desc}'.\")\n",
    "    else:\n",
    "        print(f\"No data dictionary entry found for column '{col}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid data dictionary entry: NAME: SolarSurvey.csv\n",
      "Invalid data dictionary entry: TYPE: Sample\n",
      "Invalid data dictionary entry: SIZE: 3000 observations, 13 variables\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: --------------------------------------------------------\n",
      "Invalid data dictionary entry: DATA FILE DESCRIPTION:\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: The data file is a standard CSV with comma delimiters.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: --------------------------------------------------------\n",
      "Invalid data dictionary entry: DATA COLLECTION:\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: The data is a combination of information from the customer energy retailer,\n",
      "Invalid data dictionary entry: energy distributors and solar installers.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Sampling is limited to installations with:\n",
      "Invalid data dictionary entry: - a single solar panel array or multiple arrays that are oriented identically,\n",
      "Invalid data dictionary entry: - rooftop installation only.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: The generation from the solar panels was collected from 1/1/2022 to 31/12/2022.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: --------------------------------------------------------\n",
      "Invalid data dictionary entry: VARIABLE LISTING EXPLANATION\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Each variable name is followed by a short description. This is then optionally\n",
      "Invalid data dictionary entry: followed by a list of valid values.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: For numeric variables the valid range is provided. Where the value is not capped\n",
      "Invalid data dictionary entry: a \"?\" is used.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: --------------------------------------------------------\n",
      "Invalid data dictionary entry: VARIABLE LISTING\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Household_ID: A unique alphanumeric string assigned to each house.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: City: The greater metropolitan area of the house.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Brisbane\n",
      "Invalid data dictionary entry: Sydney\n",
      "Invalid data dictionary entry: Melbourne\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Latitude: The geographic latitude of the house, as recorded by the solar\n",
      "Invalid data dictionary entry: installer.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Min: -90\n",
      "Invalid data dictionary entry: Max: 90\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: House_Type: The main construction type of the house, as recorded by the solar\n",
      "Invalid data dictionary entry: installer.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Timber Frame\n",
      "Invalid data dictionary entry: Double Brick\n",
      "Invalid data dictionary entry: Other\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Roof_Type: The type of roof the panels were installed on, as recorded by the\n",
      "Invalid data dictionary entry: solar installer.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Tile\n",
      "Invalid data dictionary entry: Steel\n",
      "Invalid data dictionary entry: Other\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Roof_Pitch: The roof angle, as recorded by the solar installer.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Min: 0 (flat)\n",
      "Invalid data dictionary entry: Max: 90 (vertical)\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Roof_Azimuth: The angle from North that the panels are facing, as recorded by\n",
      "Invalid data dictionary entry: the solar installer.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Min: 0 (North)\n",
      "Invalid data dictionary entry: Max: 360 (North)\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Floors: The number of floors in the house, as recorded by the solar installer.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Single\n",
      "Invalid data dictionary entry: Double\n",
      "Invalid data dictionary entry: Other\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Financed: Whether the solar panel system is currently under a financing\n",
      "Invalid data dictionary entry: arrangement through the solar installer or energy retailer.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Yes\n",
      "Invalid data dictionary entry: No\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Year: The year the solar panel system was installed.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Min: 2001\n",
      "Invalid data dictionary entry: Max: 2022\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Panel_Capacity: The total capacity of the solar panel installation in Watts,\n",
      "Invalid data dictionary entry: according to the Manufacturer's datasheet. As recorded by the solar installer.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Min: 0\n",
      "Invalid data dictionary entry: Max: ?\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Shading: The amount of shading that the solar installer expects the panels to\n",
      "Invalid data dictionary entry: be subject to from the nearby environment such as trees or man made structures.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Significant\n",
      "Invalid data dictionary entry: Partial\n",
      "Invalid data dictionary entry: None\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Generation: The total generation in kilowatt hours (kWh) in the sampling period\n",
      "Invalid data dictionary entry: (from 1/1/2022 to 31/12/2022). This value collected directly from the smart\n",
      "Invalid data dictionary entry: meter and is the gross generation, meaning that customer usage has not been\n",
      "Invalid data dictionary entry: deducted.\n",
      "Invalid data dictionary entry: \n",
      "Invalid data dictionary entry: Min: 0\n",
      "Invalid data dictionary entry: Max: ?\n",
      "No data dictionary entry found for column 'Household_ID'.\n",
      "No data dictionary entry found for column 'City'.\n",
      "No data dictionary entry found for column 'Latitude'.\n",
      "No data dictionary entry found for column 'House_Type'.\n",
      "No data dictionary entry found for column 'Roof_Type'.\n",
      "No data dictionary entry found for column 'Roof_Pitch'.\n",
      "No data dictionary entry found for column 'Roof_Azimuth'.\n",
      "No data dictionary entry found for column 'Floors'.\n",
      "No data dictionary entry found for column 'Financed'.\n",
      "No data dictionary entry found for column 'Year'.\n",
      "No data dictionary entry found for column 'Panel_Capacity'.\n",
      "No data dictionary entry found for column 'Shading'.\n",
      "No data dictionary entry found for column 'Generation'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:/Users/Faraz Ahmad/Downloads/SolarSurvey.csv\")\n",
    "\n",
    "# Load your data dictionary into a list\n",
    "with open(\"C:/Users/Faraz Ahmad/Downloads/DataDictionary.txt\", \"r\") as f:\n",
    "    dict_lines = f.readlines()\n",
    "\n",
    "# Create a dictionary to store the data types and descriptions\n",
    "# for each column in the data dictionary\n",
    "dict_cols = {}\n",
    "for line in dict_lines:\n",
    "    parts = line.strip().split(\":\")\n",
    "    if len(parts) == 3:\n",
    "        dict_cols[parts[0]] = {\"type\": parts[1], \"description\": parts[2]}\n",
    "    else:\n",
    "        print(f\"Invalid data dictionary entry: {line.strip()}\")\n",
    "\n",
    "# Loop through each column in the dataset and compare the data type\n",
    "# and description to the data dictionary\n",
    "for col in df.columns:\n",
    "    if col in dict_cols:\n",
    "        data_type = str(df[col].dtype)\n",
    "        dict_type = dict_cols[col][\"type\"]\n",
    "        if data_type != dict_type:\n",
    "            print(f\"Data type for column '{col}' does not match data dictionary. Expected {dict_type}, got {data_type}.\")\n",
    "\n",
    "        data_desc = df[col].describe().loc['top']\n",
    "        dict_desc = dict_cols[col][\"description\"]\n",
    "        if data_desc != dict_desc:\n",
    "            print(f\"Description for column '{col}' does not match data dictionary. Expected '{dict_desc}', got '{data_desc}'.\")\n",
    "    else:\n",
    "        print(f\"No data dictionary entry found for column '{col}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7c6ce67c5579>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdict_cols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"description\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Loop through each column in the dataset and compare the data type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:/Users/Faraz Ahmad/Downloads/SolarSurvey.csv\")\n",
    "\n",
    "# Load your data dictionary into a list\n",
    "with open(\"C:/Users/Faraz Ahmad/Downloads/DataDictionary.txt\", \"r\") as f:\n",
    "    dict_lines = f.readlines()\n",
    "\n",
    "# Create a dictionary to store the data types and descriptions\n",
    "# for each column in the data dictionary\n",
    "dict_cols = {}\n",
    "for line in dict_lines:\n",
    "    parts = line.strip().split(\":\")\n",
    "    dict_cols[parts[0]] = {\"type\": parts[1], \"description\": parts[2]}\n",
    "\n",
    "# Loop through each column in the dataset and compare the data type\n",
    "# and description to the data dictionary\n",
    "for col in df.columns:\n",
    "    if col in dict_cols:\n",
    "        data_type = str(df[col].dtype)\n",
    "        dict_type = dict_cols[col][\"type\"]\n",
    "        if data_type != dict_type:\n",
    "            print(f\"Data type for column '{col}' does not match data dictionary. Expected {dict_type}, got {data_type}.\")\n",
    "\n",
    "        data_desc = df[col].describe().loc['top']\n",
    "        dict_desc = dict_cols[col][\"description\"]\n",
    "        if data_desc != dict_desc:\n",
    "            print(f\"Description for column '{col}' does not match data dictionary. Expected '{dict_desc}', got '{data_desc}'.\")\n",
    "    else:\n",
    "        print(f\"No data dictionary entry found for column '{col}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'histplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-002cf8e2e6aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Histogram of Generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Generation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'histplot'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:/Users/Faraz Ahmad/Downloads/SolarSurvey.csv\")\n",
    "\n",
    "# Histogram of Generation\n",
    "sns.histplot(data=df, x=\"Generation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
